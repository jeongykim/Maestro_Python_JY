{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0+cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1,2],[3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_f = torch.FloatTensor(data)\n",
    "x_data_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_f.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_f.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_f[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_f[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_f[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 7.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.FloatTensor([[3,3]])\n",
    "t2 = torch.FloatTensor([[2,4]])\n",
    "print(t1 + t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_f.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_f.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5000, 3.5000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_f.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.FloatTensor([[1,3]])\n",
    "t2 = torch.FloatTensor([[2,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3.],\n",
       "        [2., 4.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([t1,t2], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3., 2., 4.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([t1,t2], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 3.]],\n",
       "\n",
       "        [[2., 4.]],\n",
       "\n",
       "        [[5., 6.]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = torch.FloatTensor([[5,6]])\n",
    "t4 = torch.stack([t1,t2,t3])\n",
    "t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.]],\n",
       "\n",
       "        [[0., 0.]],\n",
       "\n",
       "        [[0., 0.]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 가설 설정\n",
    "- y=W*x+b (b = bias)\n",
    "- 기존 머신러닝: MSE평균제곱오차\n",
    "\n",
    "## 딥러닝 세상의 인식 체계\n",
    "- cost function(비용함수)=loss function(손실함수)\n",
    "- = error function(오차 함수) = objective function(목적함수)\n",
    "- 옵티마이저는 경사하강법(Gradient Descent)을 사용 (Ex. 머신러닝에서 fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.],\n",
      "        [4.],\n",
      "        [6.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 초기화 시키는 작업\n",
    "W = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "b = torch.zeros(1,requires_grad = True)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 현재의 상태\n",
    "- y = 0*x+0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 수식 설정 y = (X_train)*W + b\n",
    "hypothesis = X_train*W+b\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18.6667, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#평균 제곱 오차\n",
    "cost = torch.mean((hypothesis-y_train)**2)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD([W, b], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "cost.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0/20000 W:0.019, b:0.008 cost:18.66667\n",
      "Epoch 200/20000 W:1.513, b:0.624 cost:0.28531\n",
      "Epoch 400/20000 W:1.686, b:0.661 cost:0.06679\n",
      "Epoch 600/20000 W:1.717, b:0.637 cost:0.05845\n",
      "Epoch 800/20000 W:1.732, b:0.608 cost:0.05306\n",
      "Epoch1000/20000 W:1.745, b:0.579 cost:0.04820\n",
      "Epoch1200/20000 W:1.757, b:0.552 cost:0.04378\n",
      "Epoch1400/20000 W:1.768, b:0.526 cost:0.03976\n",
      "Epoch1600/20000 W:1.779, b:0.502 cost:0.03612\n",
      "Epoch1800/20000 W:1.790, b:0.478 cost:0.03281\n",
      "Epoch2000/20000 W:1.800, b:0.456 cost:0.02980\n",
      "Epoch2200/20000 W:1.809, b:0.434 cost:0.02707\n",
      "Epoch2400/20000 W:1.818, b:0.414 cost:0.02458\n",
      "Epoch2600/20000 W:1.826, b:0.394 cost:0.02233\n",
      "Epoch2800/20000 W:1.835, b:0.376 cost:0.02028\n",
      "Epoch3000/20000 W:1.842, b:0.358 cost:0.01842\n",
      "Epoch3200/20000 W:1.850, b:0.341 cost:0.01673\n",
      "Epoch3400/20000 W:1.857, b:0.325 cost:0.01520\n",
      "Epoch3600/20000 W:1.864, b:0.310 cost:0.01381\n",
      "Epoch3800/20000 W:1.870, b:0.296 cost:0.01254\n",
      "Epoch4000/20000 W:1.876, b:0.282 cost:0.01139\n",
      "Epoch4200/20000 W:1.882, b:0.268 cost:0.01035\n",
      "Epoch4400/20000 W:1.887, b:0.256 cost:0.00940\n",
      "Epoch4600/20000 W:1.893, b:0.244 cost:0.00854\n",
      "Epoch4800/20000 W:1.898, b:0.232 cost:0.00775\n",
      "Epoch5000/20000 W:1.903, b:0.222 cost:0.00704\n",
      "Epoch5200/20000 W:1.907, b:0.211 cost:0.00640\n",
      "Epoch5400/20000 W:1.911, b:0.201 cost:0.00581\n",
      "Epoch5600/20000 W:1.916, b:0.192 cost:0.00528\n",
      "Epoch5800/20000 W:1.920, b:0.183 cost:0.00479\n",
      "Epoch6000/20000 W:1.923, b:0.174 cost:0.00435\n",
      "Epoch6200/20000 W:1.927, b:0.166 cost:0.00395\n",
      "Epoch6400/20000 W:1.930, b:0.158 cost:0.00359\n",
      "Epoch6600/20000 W:1.934, b:0.151 cost:0.00326\n",
      "Epoch6800/20000 W:1.937, b:0.144 cost:0.00296\n",
      "Epoch7000/20000 W:1.940, b:0.137 cost:0.00269\n",
      "Epoch7200/20000 W:1.943, b:0.131 cost:0.00245\n",
      "Epoch7400/20000 W:1.945, b:0.124 cost:0.00222\n",
      "Epoch7600/20000 W:1.948, b:0.119 cost:0.00202\n",
      "Epoch7800/20000 W:1.950, b:0.113 cost:0.00183\n",
      "Epoch8000/20000 W:1.953, b:0.108 cost:0.00166\n",
      "Epoch8200/20000 W:1.955, b:0.103 cost:0.00151\n",
      "Epoch8400/20000 W:1.957, b:0.098 cost:0.00137\n",
      "Epoch8600/20000 W:1.959, b:0.093 cost:0.00125\n",
      "Epoch8800/20000 W:1.961, b:0.089 cost:0.00113\n",
      "Epoch9000/20000 W:1.963, b:0.085 cost:0.00103\n",
      "Epoch9200/20000 W:1.965, b:0.081 cost:0.00093\n",
      "Epoch9400/20000 W:1.966, b:0.077 cost:0.00085\n",
      "Epoch9600/20000 W:1.968, b:0.073 cost:0.00077\n",
      "Epoch9800/20000 W:1.969, b:0.070 cost:0.00070\n",
      "Epoch10000/20000 W:1.971, b:0.067 cost:0.00064\n",
      "Epoch10200/20000 W:1.972, b:0.063 cost:0.00058\n",
      "Epoch10400/20000 W:1.973, b:0.060 cost:0.00052\n",
      "Epoch10600/20000 W:1.975, b:0.058 cost:0.00048\n",
      "Epoch10800/20000 W:1.976, b:0.055 cost:0.00043\n",
      "Epoch11000/20000 W:1.977, b:0.052 cost:0.00039\n",
      "Epoch11200/20000 W:1.978, b:0.050 cost:0.00036\n",
      "Epoch11400/20000 W:1.979, b:0.048 cost:0.00032\n",
      "Epoch11600/20000 W:1.980, b:0.045 cost:0.00029\n",
      "Epoch11800/20000 W:1.981, b:0.043 cost:0.00027\n",
      "Epoch12000/20000 W:1.982, b:0.041 cost:0.00024\n",
      "Epoch12200/20000 W:1.983, b:0.039 cost:0.00022\n",
      "Epoch12400/20000 W:1.984, b:0.037 cost:0.00020\n",
      "Epoch12600/20000 W:1.984, b:0.036 cost:0.00018\n",
      "Epoch12800/20000 W:1.985, b:0.034 cost:0.00017\n",
      "Epoch13000/20000 W:1.986, b:0.032 cost:0.00015\n",
      "Epoch13200/20000 W:1.986, b:0.031 cost:0.00014\n",
      "Epoch13400/20000 W:1.987, b:0.029 cost:0.00012\n",
      "Epoch13600/20000 W:1.988, b:0.028 cost:0.00011\n",
      "Epoch13800/20000 W:1.988, b:0.027 cost:0.00010\n",
      "Epoch14000/20000 W:1.989, b:0.025 cost:0.00009\n",
      "Epoch14200/20000 W:1.989, b:0.024 cost:0.00008\n",
      "Epoch14400/20000 W:1.990, b:0.023 cost:0.00008\n",
      "Epoch14600/20000 W:1.990, b:0.022 cost:0.00007\n",
      "Epoch14800/20000 W:1.991, b:0.021 cost:0.00006\n",
      "Epoch15000/20000 W:1.991, b:0.020 cost:0.00006\n",
      "Epoch15200/20000 W:1.992, b:0.019 cost:0.00005\n",
      "Epoch15400/20000 W:1.992, b:0.018 cost:0.00005\n",
      "Epoch15600/20000 W:1.992, b:0.017 cost:0.00004\n",
      "Epoch15800/20000 W:1.993, b:0.017 cost:0.00004\n",
      "Epoch16000/20000 W:1.993, b:0.016 cost:0.00004\n",
      "Epoch16200/20000 W:1.993, b:0.015 cost:0.00003\n",
      "Epoch16400/20000 W:1.994, b:0.014 cost:0.00003\n",
      "Epoch16600/20000 W:1.994, b:0.014 cost:0.00003\n",
      "Epoch16800/20000 W:1.994, b:0.013 cost:0.00002\n",
      "Epoch17000/20000 W:1.995, b:0.012 cost:0.00002\n",
      "Epoch17200/20000 W:1.995, b:0.012 cost:0.00002\n",
      "Epoch17400/20000 W:1.995, b:0.011 cost:0.00002\n",
      "Epoch17600/20000 W:1.995, b:0.011 cost:0.00002\n",
      "Epoch17800/20000 W:1.995, b:0.010 cost:0.00002\n",
      "Epoch18000/20000 W:1.996, b:0.010 cost:0.00001\n",
      "Epoch18200/20000 W:1.996, b:0.009 cost:0.00001\n",
      "Epoch18400/20000 W:1.996, b:0.009 cost:0.00001\n",
      "Epoch18600/20000 W:1.996, b:0.008 cost:0.00001\n",
      "Epoch18800/20000 W:1.996, b:0.008 cost:0.00001\n",
      "Epoch19000/20000 W:1.997, b:0.008 cost:0.00001\n",
      "Epoch19200/20000 W:1.997, b:0.007 cost:0.00001\n",
      "Epoch19400/20000 W:1.997, b:0.007 cost:0.00001\n",
      "Epoch19600/20000 W:1.997, b:0.007 cost:0.00001\n",
      "Epoch19800/20000 W:1.997, b:0.006 cost:0.00001\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "X_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])\n",
    "\n",
    "# 썼던 수식들 초기화 함수들 W,b\n",
    "W = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1,requires_grad = True)\n",
    "\n",
    "optimizer = optim.SGD([W, b], lr=0.001) #lr learning rate\n",
    "\n",
    "nb_epochs = 20000   #실행을 충분히 하기위해 많이 돌려봄\n",
    "list_cost = []\n",
    "for epoch in range(nb_epochs):\n",
    "    hypothesis = X_train*W+b \n",
    "    cost = torch.mean((hypothesis-y_train)**2)\n",
    "  \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 200 == 0:\n",
    "        list_cost.append(cost.item())\n",
    "        print('Epoch{:4d}/{} W:{:.3f}, b:{:.3f} cost:{:.5f}'.format(epoch,nb_epochs,W.item(),b.item(),cost.item()))\n",
    "\n",
    "#print(list_cost)\n",
    "#plt.plot(range(100),list_cost,marker='x') 커널 나가서 그림으로 안그림\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 가설 설정 : x가 3개인 다변량 회귀\n",
    "- y =W1*x1 +W2*x2 +W3*x3 +b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0/600000 W1:0.029,W2:0.029,W3:0.030, b:0.000 cost:29661.80078\n",
      "Epoch20000/600000 W1:0.757,W2:0.571,W3:0.682, b:0.011 cost:0.75468\n",
      "Epoch40000/600000 W1:0.812,W2:0.517,W3:0.681, b:0.013 cost:0.44871\n",
      "Epoch60000/600000 W1:0.848,W2:0.488,W3:0.675, b:0.015 cost:0.33744\n",
      "Epoch80000/600000 W1:0.871,W2:0.472,W3:0.667, b:0.018 cost:0.29273\n",
      "Epoch100000/600000 W1:0.888,W2:0.464,W3:0.658, b:0.020 cost:0.27120\n",
      "Epoch120000/600000 W1:0.901,W2:0.461,W3:0.649, b:0.021 cost:0.25803\n",
      "Epoch140000/600000 W1:0.911,W2:0.461,W3:0.639, b:0.023 cost:0.24828\n",
      "Epoch160000/600000 W1:0.919,W2:0.462,W3:0.630, b:0.025 cost:0.24010\n",
      "Epoch180000/600000 W1:0.927,W2:0.464,W3:0.621, b:0.027 cost:0.23309\n",
      "Epoch200000/600000 W1:0.933,W2:0.466,W3:0.612, b:0.028 cost:0.22697\n",
      "Epoch220000/600000 W1:0.939,W2:0.468,W3:0.604, b:0.030 cost:0.22126\n",
      "Epoch240000/600000 W1:0.945,W2:0.471,W3:0.596, b:0.032 cost:0.21588\n",
      "Epoch260000/600000 W1:0.950,W2:0.473,W3:0.588, b:0.033 cost:0.21143\n",
      "Epoch280000/600000 W1:0.955,W2:0.476,W3:0.581, b:0.035 cost:0.20725\n",
      "Epoch300000/600000 W1:0.959,W2:0.478,W3:0.574, b:0.036 cost:0.20330\n",
      "Epoch320000/600000 W1:0.964,W2:0.480,W3:0.567, b:0.037 cost:0.19969\n",
      "Epoch340000/600000 W1:0.968,W2:0.482,W3:0.561, b:0.039 cost:0.19664\n",
      "Epoch360000/600000 W1:0.972,W2:0.484,W3:0.555, b:0.040 cost:0.19378\n",
      "Epoch380000/600000 W1:0.976,W2:0.486,W3:0.550, b:0.041 cost:0.19115\n",
      "Epoch400000/600000 W1:0.980,W2:0.488,W3:0.544, b:0.042 cost:0.18881\n",
      "Epoch420000/600000 W1:0.983,W2:0.489,W3:0.539, b:0.044 cost:0.18669\n",
      "Epoch440000/600000 W1:0.986,W2:0.491,W3:0.535, b:0.045 cost:0.18477\n",
      "Epoch460000/600000 W1:0.990,W2:0.492,W3:0.530, b:0.046 cost:0.18295\n",
      "Epoch480000/600000 W1:0.993,W2:0.494,W3:0.525, b:0.047 cost:0.18123\n",
      "Epoch500000/600000 W1:0.995,W2:0.496,W3:0.521, b:0.048 cost:0.17981\n",
      "Epoch520000/600000 W1:0.998,W2:0.497,W3:0.517, b:0.049 cost:0.17862\n",
      "Epoch540000/600000 W1:1.000,W2:0.498,W3:0.514, b:0.050 cost:0.17747\n",
      "Epoch560000/600000 W1:1.003,W2:0.499,W3:0.510, b:0.051 cost:0.17638\n",
      "Epoch580000/600000 W1:1.005,W2:0.500,W3:0.507, b:0.052 cost:0.17534\n"
     ]
    }
   ],
   "source": [
    "X1_train = torch.FloatTensor([[73],[93],[89],[96],[73]])\n",
    "X2_train = torch.FloatTensor([[80],[88],[91],[98],[66]])\n",
    "X3_train = torch.FloatTensor([[75],[93],[90],[100],[70]])\n",
    "y_train = torch.FloatTensor([[152],[185],[180],[196],[142]])\n",
    "\n",
    "W1 = torch.zeros(1, requires_grad=True)\n",
    "W2 = torch.zeros(1, requires_grad=True)\n",
    "W3 = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1,requires_grad = True)\n",
    "\n",
    "optimizer = optim.SGD([W1,W2,W3, b], lr= 0.000001)\n",
    "nb_epochs=600000\n",
    "for epoch in range(nb_epochs):\n",
    "    hypothesis = (X1_train*W1)+(X2_train*W2)+(X3_train*W3)+b \n",
    "    cost = torch.mean((hypothesis-y_train)**2)\n",
    "  \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 20000 == 0:\n",
    "        list_cost.append(cost.item())\n",
    "        print('Epoch{:4d}/{} W1:{:.3f},W2:{:.3f},W3:{:.3f}, b:{:.3f} cost:{:.5f}'.format(epoch,nb_epochs,W1.item(),W2.item(),W3.item(),b.item(),cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론 :learning rate와 epoch 값을 유동적으로 넣어가며 최적의(0에 수렴하는) cost값을 찾아내야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1,1) #(input_dim=1,output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.6123]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.9747], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())) # [Parameter containing:\n",
    "#                                 tensor([[W값]], requires_grad=True), Parameter containing:\n",
    "#                                 tensor([b값], requires_grad=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0/2000 loss:4.74249\n",
      "Epoch 100/2000 loss:0.01607\n",
      "Epoch 200/2000 loss:0.00993\n",
      "Epoch 300/2000 loss:0.00614\n",
      "Epoch 400/2000 loss:0.00379\n",
      "Epoch 500/2000 loss:0.00234\n",
      "Epoch 600/2000 loss:0.00145\n",
      "Epoch 700/2000 loss:0.00089\n",
      "Epoch 800/2000 loss:0.00055\n",
      "Epoch 900/2000 loss:0.00034\n",
      "Epoch1000/2000 loss:0.00021\n",
      "Epoch1100/2000 loss:0.00013\n",
      "Epoch1200/2000 loss:0.00008\n",
      "Epoch1300/2000 loss:0.00005\n",
      "Epoch1400/2000 loss:0.00003\n",
      "Epoch1500/2000 loss:0.00002\n",
      "Epoch1600/2000 loss:0.00001\n",
      "Epoch1700/2000 loss:0.00001\n",
      "Epoch1800/2000 loss:0.00000\n",
      "Epoch1900/2000 loss:0.00000\n",
      "Epoch2000/2000 loss:0.00000\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "X_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])\n",
    "model =nn.Linear(1,1)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "\n",
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs+1):\n",
    "    prediction = model(X_train)\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch{:4d}/{} loss:{:.5f}'.format(epoch,nb_epochs,cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 계속 시행값이 달라지는 이유\n",
    "- optimizer 함수가 값을 산출할 때 w값에 대한 계산을 랜덤으로 가져간다. \n",
    "- 그래서 똑같은 learning mate 값과 epoch를 넣고 돌릴때 계속 달라지는 이유이다. \n",
    "- 그래서 y_pred 값이 산출 될 때 계속 조금씩 값이 틀려지는 이유이다.\n",
    "- 이것은 잘못된 것이 아니다.\n",
    "\n",
    "## 내가 제시한 방향성\n",
    "- 값들을 계속 돌려보면서 나오는 값들의 평균값을 알려준다.\n",
    "\n",
    "## 강사님의 말씀\n",
    "- 더욱 정확한 값을 원하면 x_train, y_train 값을 정밀하게 가져가서 값을 찾는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0012]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 데이터를 FloatTensor에 넣고 예측값을 산출해본다.\n",
    "new_input = torch.FloatTensor([[1.5]])\n",
    "pred_y = model(new_input)\n",
    "pred_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
