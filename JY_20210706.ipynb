{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct, os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind=\"train\"):\n",
    "    labels_path = os.path.join(path, \"%s-labels-idx1-ubyte\"%kind)\n",
    "    images_path = os.path.join(path, \"%s-images-idx3-ubyte\"%kind)\n",
    "    #label\n",
    "    with open(labels_path,\"rb\")as la_path:\n",
    "        magic,n = struct.unpack(\">II\",la_path.read(8))\n",
    "        labels = np.fromfile(la_path, dtype=np.uint8)\n",
    "    #image\n",
    "    with open(images_path,\"rb\") as img_path:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\",img_path.read(16))\n",
    "        images = np.fromfile(img_path, dtype=np.uint8).reshape(len(labels), 28**2)\n",
    "        images = ((images/255) - 0.5)*2\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 784\n",
      "10000 784\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_mnist(\"./\", kind=\"train\")\n",
    "X_test, y_test = load_mnist(\"./\", kind=\"t10k\")\n",
    "print(X_train.shape[0], X_train.shape[1])\n",
    "print(X_test.shape[0], X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vals = np.mean(X_train, axis=0)\n",
    "std_val = np.std(X_train)\n",
    "X_train_centered = (X_train-mean_vals)/std_val\n",
    "X_test_centered = (X_test-mean_vals)/std_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_onehot = tf.keras.utils.to_categorical(y_train)\n",
    "y_train_onehot[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        units = 50,          ## 파생되는 신경망1의 개수 50개\n",
    "        input_dim = X_train_centered.shape[1],\n",
    "        kernel_initializer = 'glorot_uniform',  ## W(가중치)\n",
    "        bias_initializer = 'zeros',  ## b\n",
    "        activation=\"tanh\"  ## 전달함수 , 파이토치에서는 렐루 함수와 동일 / 하이퍼볼릭 탄젠트\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        units = 50,           ## 파생되는 신경망2의 개수 50개 작게 잡으면 처리속도가 빠르게 계산되지만 값이 희미해질 수 있고, 많아도 비슷함, 최적화된 수를 찾아주는것이 제일 좋은 방법\n",
    "        input_dim = 50,\n",
    "        kernel_initializer = 'glorot_uniform',  ## W(가중치)\n",
    "        bias_initializer = 'zeros',  ## b\n",
    "        activation=\"tanh\"\n",
    ")\n",
    ")\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        units = 10,       ## 파생되어 산출되는 마지막 신경망3의 개수 10개\n",
    "        input_dim = 50,\n",
    "        kernel_initializer = 'glorot_uniform',  ## W(가중치)\n",
    "        bias_initializer = 'zeros',  ## b\n",
    "        activation=\"softmax\"  ## 다 합치면 1 하나의 확률변수\n",
    ")\n",
    ")\n"
   ]
  },
  {
   "attachments": {
    "images.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![images.jpg](attachment:images.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense가 히든 레이어 수, Shape이 펼쳐진 가지 수,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 42,310\n",
      "Trainable params: 42,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.0001,decay=1e-7,momentum=0.9)\n",
    "model.compile(optimizer=sgd_optimizer, loss = \"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 1.6313 - val_loss: 1.1242\n",
      "Epoch 2/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 1.0060 - val_loss: 0.8101\n",
      "Epoch 3/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.7957 - val_loss: 0.6592\n",
      "Epoch 4/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.6796 - val_loss: 0.5678\n",
      "Epoch 5/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.6039 - val_loss: 0.5061\n",
      "Epoch 6/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.5503 - val_loss: 0.4618\n",
      "Epoch 7/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.5103 - val_loss: 0.4285\n",
      "Epoch 8/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.4792 - val_loss: 0.4024\n",
      "Epoch 9/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.4541 - val_loss: 0.3813\n",
      "Epoch 10/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.4335 - val_loss: 0.3641\n",
      "Epoch 11/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.4161 - val_loss: 0.3496\n",
      "Epoch 12/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.4012 - val_loss: 0.3371\n",
      "Epoch 13/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3882 - val_loss: 0.3262\n",
      "Epoch 14/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3768 - val_loss: 0.3167\n",
      "Epoch 15/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3665 - val_loss: 0.3083\n",
      "Epoch 16/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3573 - val_loss: 0.3006\n",
      "Epoch 17/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3489 - val_loss: 0.2936\n",
      "Epoch 18/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3413 - val_loss: 0.2873\n",
      "Epoch 19/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3342 - val_loss: 0.2815\n",
      "Epoch 20/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3277 - val_loss: 0.2761\n",
      "Epoch 21/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3216 - val_loss: 0.2711\n",
      "Epoch 22/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3159 - val_loss: 0.2664\n",
      "Epoch 23/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3105 - val_loss: 0.2621\n",
      "Epoch 24/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3055 - val_loss: 0.2580\n",
      "Epoch 25/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3007 - val_loss: 0.2543\n",
      "Epoch 26/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2962 - val_loss: 0.2506\n",
      "Epoch 27/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2919 - val_loss: 0.2471\n",
      "Epoch 28/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2878 - val_loss: 0.2438\n",
      "Epoch 29/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2839 - val_loss: 0.2407\n",
      "Epoch 30/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2802 - val_loss: 0.2377\n",
      "Epoch 31/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2766 - val_loss: 0.2350\n",
      "Epoch 32/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2732 - val_loss: 0.2322\n",
      "Epoch 33/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2699 - val_loss: 0.2296\n",
      "Epoch 34/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2667 - val_loss: 0.2272\n",
      "Epoch 35/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2636 - val_loss: 0.2247\n",
      "Epoch 36/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2607 - val_loss: 0.2225\n",
      "Epoch 37/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2578 - val_loss: 0.2202\n",
      "Epoch 38/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2551 - val_loss: 0.2181\n",
      "Epoch 39/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2524 - val_loss: 0.2161\n",
      "Epoch 40/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2498 - val_loss: 0.2142\n",
      "Epoch 41/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2473 - val_loss: 0.2122\n",
      "Epoch 42/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2449 - val_loss: 0.2104\n",
      "Epoch 43/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2425 - val_loss: 0.2086\n",
      "Epoch 44/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2402 - val_loss: 0.2069\n",
      "Epoch 45/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2380 - val_loss: 0.2052\n",
      "Epoch 46/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2358 - val_loss: 0.2035\n",
      "Epoch 47/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2337 - val_loss: 0.2020\n",
      "Epoch 48/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2316 - val_loss: 0.2005\n",
      "Epoch 49/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2296 - val_loss: 0.1990\n",
      "Epoch 50/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2277 - val_loss: 0.1975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x149aca5d070>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_centered,y_train_onehot, batch_size=64,epochs=50,\n",
    "         verbose=1,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train_centered,verbose=0)\n",
    "y_train_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56276\n",
      "0.9379333333333333\n"
     ]
    }
   ],
   "source": [
    "# 예측한 것이 몇개나 맞췄을까?\n",
    "total_predicts = np.sum(y_train==y_train_pred,axis=0)\n",
    "print(total_predicts)\n",
    "train_res = total_predicts/y_train.shape[0]\n",
    "print(train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = model.predict_classes(X_test_centered,verbose=0)\n",
    "y_test_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9337\n",
      "0.9337\n"
     ]
    }
   ],
   "source": [
    "# 예측한 것이 몇개나 맞췄을까?\n",
    "total_predicts = np.sum(y_test==y_test_pred,axis=0)\n",
    "print(total_predicts)\n",
    "test_res = total_predicts/y_test.shape[0]\n",
    "print(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 5 6 다름\n",
      "38 2 3 다름\n",
      "63 3 2 다름\n",
      "66 6 7 다름\n",
      "73 9 7 다름\n",
      "77 2 7 다름\n",
      "124 7 4 다름\n",
      "126 0 2 다름\n",
      "149 2 4 다름\n",
      "193 9 4 다름\n",
      "195 3 5 다름\n",
      "217 6 5 다름\n",
      "233 8 7 다름\n",
      "241 9 8 다름\n",
      "247 4 2 다름\n",
      "259 6 0 다름\n",
      "290 8 4 다름\n",
      "300 4 6 다름\n",
      "313 3 5 다름\n",
      "320 9 7 다름\n",
      "321 2 7 다름\n",
      "325 4 9 다름\n",
      "340 5 3 다름\n",
      "341 6 4 다름\n",
      "352 5 0 다름\n",
      "358 7 9 다름\n",
      "362 2 3 다름\n",
      "380 0 5 다름\n",
      "381 3 7 다름\n",
      "435 8 7 다름\n",
      "444 2 8 다름\n",
      "445 6 0 다름\n",
      "448 9 8 다름\n",
      "449 3 5 다름\n",
      "478 5 8 다름\n",
      "479 9 3 다름\n",
      "495 8 2 다름\n",
      "502 5 3 다름\n",
      "507 3 5 다름\n",
      "528 3 2 다름\n",
      "542 8 2 다름\n",
      "543 8 3 다름\n",
      "551 7 1 다름\n",
      "565 4 9 다름\n",
      "578 3 8 다름\n",
      "582 8 2 다름\n",
      "591 8 3 다름\n",
      "613 2 8 다름\n",
      "619 1 8 다름\n",
      "628 3 9 다름\n",
      "629 2 6 다름\n",
      "659 2 8 다름\n",
      "684 7 3 다름\n",
      "689 7 9 다름\n",
      "691 8 4 다름\n",
      "692 5 7 다름\n",
      "707 4 9 다름\n",
      "717 0 6 다름\n",
      "720 5 8 다름\n",
      "740 4 9 다름\n",
      "741 2 8 다름\n",
      "760 4 9 다름\n",
      "791 5 9 다름\n",
      "839 8 3 다름\n",
      "844 8 7 다름\n",
      "874 9 4 다름\n",
      "881 4 9 다름\n",
      "882 9 7 다름\n",
      "924 2 7 다름\n",
      "938 3 5 다름\n",
      "939 2 0 다름\n",
      "947 8 9 다름\n",
      "950 7 2 다름\n",
      "956 1 6 다름\n",
      "959 4 9 다름\n",
      "960 7 1 다름\n",
      "965 6 0 다름\n",
      "982 3 2 다름\n",
      "1003 5 3 다름\n",
      "1014 6 5 다름\n",
      "1032 5 8 다름\n",
      "1039 7 9 다름\n",
      "1044 6 8 다름\n",
      "1050 2 6 다름\n",
      "1052 8 9 다름\n",
      "1062 3 7 다름\n",
      "1068 8 4 다름\n",
      "1082 5 3 다름\n",
      "1107 9 3 다름\n",
      "1112 4 6 다름\n",
      "1114 3 8 다름\n",
      "1119 7 2 다름\n",
      "1128 3 7 다름\n",
      "1173 7 9 다름\n",
      "1181 6 1 다름\n",
      "1182 6 8 다름\n",
      "1191 0 6 다름\n",
      "1192 9 4 다름\n",
      "1198 8 4 다름\n",
      "1200 8 3 다름\n",
      "1202 8 5 다름\n",
      "1204 3 8 다름\n",
      "1206 7 2 다름\n",
      "1224 2 6 다름\n",
      "1226 7 2 다름\n",
      "1228 9 3 다름\n",
      "1232 9 6 다름\n",
      "1242 4 9 다름\n",
      "1247 9 5 다름\n",
      "1248 8 5 다름\n",
      "1256 2 8 다름\n",
      "1260 7 1 다름\n",
      "1270 4 9 다름\n",
      "1272 5 4 다름\n",
      "1283 7 2 다름\n",
      "1289 5 9 다름\n",
      "1299 5 7 다름\n",
      "1315 3 5 다름\n",
      "1319 8 3 다름\n",
      "1325 8 6 다름\n",
      "1326 7 2 다름\n",
      "1328 7 9 다름\n",
      "1337 2 6 다름\n",
      "1378 5 6 다름\n",
      "1393 5 3 다름\n",
      "1402 2 7 다름\n",
      "1403 1 8 다름\n",
      "1414 9 4 다름\n",
      "1429 9 4 다름\n",
      "1433 8 3 다름\n",
      "1440 4 9 다름\n",
      "1444 6 4 다름\n",
      "1454 0 5 다름\n",
      "1465 4 6 다름\n",
      "1466 5 3 다름\n",
      "1467 5 9 다름\n",
      "1494 7 9 다름\n",
      "1500 7 1 다름\n",
      "1522 7 9 다름\n",
      "1525 5 0 다름\n",
      "1527 1 6 다름\n",
      "1530 8 7 다름\n",
      "1549 4 6 다름\n",
      "1553 9 3 다름\n",
      "1569 6 4 다름\n",
      "1581 7 9 다름\n",
      "1587 6 5 다름\n",
      "1596 9 4 다름\n",
      "1609 2 4 다름\n",
      "1621 0 6 다름\n",
      "1626 6 5 다름\n",
      "1634 4 7 다름\n",
      "1640 9 4 다름\n",
      "1678 2 0 다름\n",
      "1681 3 7 다름\n",
      "1686 8 5 다름\n",
      "1696 2 6 다름\n",
      "1709 9 5 다름\n",
      "1717 8 0 다름\n",
      "1718 7 3 다름\n",
      "1737 5 2 다름\n",
      "1754 7 2 다름\n",
      "1759 8 6 다름\n",
      "1765 3 5 다름\n",
      "1772 7 4 다름\n",
      "1773 1 5 다름\n",
      "1774 8 5 다름\n",
      "1782 8 2 다름\n",
      "1790 2 7 다름\n",
      "1800 6 4 다름\n",
      "1813 8 5 다름\n",
      "1850 8 9 다름\n",
      "1855 8 9 다름\n",
      "1857 6 4 다름\n",
      "1878 8 3 다름\n",
      "1883 7 9 다름\n",
      "1901 9 4 다름\n",
      "1913 3 2 다름\n",
      "1917 5 8 다름\n",
      "1930 2 4 다름\n",
      "1938 4 6 다름\n",
      "1942 8 5 다름\n",
      "1952 9 5 다름\n",
      "1968 8 1 다름\n",
      "1970 5 3 다름\n",
      "1973 8 5 다름\n",
      "1981 6 4 다름\n",
      "1982 6 5 다름\n",
      "1984 2 0 다름\n",
      "2016 7 2 다름\n",
      "2024 7 9 다름\n",
      "2033 0 5 다름\n",
      "2035 5 3 다름\n",
      "2040 5 4 다름\n",
      "2043 4 8 다름\n",
      "2044 2 7 다름\n",
      "2053 4 9 다름\n",
      "2070 7 9 다름\n",
      "2093 8 1 다름\n",
      "2098 2 0 다름\n",
      "2109 3 7 다름\n",
      "2118 6 5 다름\n",
      "2129 9 2 다름\n",
      "2130 4 9 다름\n",
      "2135 6 1 다름\n",
      "2174 3 5 다름\n",
      "2182 1 2 다름\n",
      "2185 0 5 다름\n",
      "2186 2 3 다름\n",
      "2189 9 1 다름\n",
      "2215 6 2 다름\n",
      "2224 5 6 다름\n",
      "2266 1 6 다름\n",
      "2272 8 0 다름\n",
      "2293 9 0 다름\n",
      "2299 2 7 다름\n",
      "2305 3 8 다름\n",
      "2325 7 3 다름\n",
      "2328 0 5 다름\n",
      "2369 5 9 다름\n",
      "2371 4 9 다름\n",
      "2378 0 2 다름\n",
      "2380 9 0 다름\n",
      "2387 9 1 다름\n",
      "2393 8 3 다름\n",
      "2395 8 3 다름\n",
      "2404 4 2 다름\n",
      "2406 9 1 다름\n",
      "2414 9 4 다름\n",
      "2422 6 7 다름\n",
      "2425 8 3 다름\n",
      "2447 4 9 다름\n",
      "2460 5 8 다름\n",
      "2473 1 8 다름\n",
      "2488 2 6 다름\n",
      "2534 3 5 다름\n",
      "2560 3 2 다름\n",
      "2573 5 8 다름\n",
      "2574 5 9 다름\n",
      "2578 7 2 다름\n",
      "2586 5 3 다름\n",
      "2598 8 2 다름\n",
      "2607 7 1 다름\n",
      "2610 2 8 다름\n",
      "2631 0 6 다름\n",
      "2648 9 0 다름\n",
      "2650 8 5 다름\n",
      "2654 6 1 다름\n",
      "2668 5 0 다름\n",
      "2670 5 8 다름\n",
      "2684 3 7 다름\n",
      "2695 7 4 다름\n",
      "2705 1 8 다름\n",
      "2713 0 8 다름\n",
      "2760 9 4 다름\n",
      "2770 3 6 다름\n",
      "2771 4 9 다름\n",
      "2832 5 3 다름\n",
      "2850 5 3 다름\n",
      "2877 4 7 다름\n",
      "2896 8 0 다름\n",
      "2906 3 5 다름\n",
      "2907 4 9 다름\n",
      "2925 5 0 다름\n",
      "2927 3 2 다름\n",
      "2945 3 7 다름\n",
      "2953 3 5 다름\n",
      "2995 6 8 다름\n",
      "3005 9 1 다름\n",
      "3060 9 7 다름\n",
      "3065 8 5 다름\n",
      "3073 1 2 다름\n",
      "3114 4 2 다름\n",
      "3117 5 9 다름\n",
      "3130 6 0 다름\n",
      "3136 7 1 다름\n",
      "3145 5 9 다름\n",
      "3189 7 4 다름\n",
      "3193 3 2 다름\n",
      "3206 8 3 다름\n",
      "3240 9 3 다름\n",
      "3269 6 0 다름\n",
      "3289 8 7 다름\n",
      "3316 7 4 다름\n",
      "3323 8 3 다름\n",
      "3329 7 2 다름\n",
      "3330 2 3 다름\n",
      "3333 7 9 다름\n",
      "3358 0 5 다름\n",
      "3369 9 7 다름\n",
      "3381 3 2 다름\n",
      "3405 4 9 다름\n",
      "3422 6 0 다름\n",
      "3468 5 4 다름\n",
      "3490 4 9 다름\n",
      "3503 9 1 다름\n",
      "3516 8 5 다름\n",
      "3520 6 4 다름\n",
      "3549 3 2 다름\n",
      "3550 6 5 다름\n",
      "3558 5 0 다름\n",
      "3559 8 5 다름\n",
      "3565 5 8 다름\n",
      "3567 8 5 다름\n",
      "3573 7 4 다름\n",
      "3575 7 4 다름\n",
      "3597 9 3 다름\n",
      "3604 7 0 다름\n",
      "3618 9 7 다름\n",
      "3629 8 3 다름\n",
      "3662 8 5 다름\n",
      "3664 9 4 다름\n",
      "3674 8 3 다름\n",
      "3688 6 5 다름\n",
      "3716 9 3 다름\n",
      "3718 4 9 다름\n",
      "3726 4 9 다름\n",
      "3730 7 9 다름\n",
      "3751 7 1 다름\n",
      "3757 8 3 다름\n",
      "3758 4 9 다름\n",
      "3767 7 2 다름\n",
      "3776 5 8 다름\n",
      "3780 4 6 다름\n",
      "3796 2 8 다름\n",
      "3806 5 8 다름\n",
      "3808 7 3 다름\n",
      "3811 2 4 다름\n",
      "3817 2 4 다름\n",
      "3818 0 6 다름\n",
      "3820 9 0 다름\n",
      "3821 9 4 다름\n",
      "3833 8 3 다름\n",
      "3834 3 2 다름\n",
      "3836 7 9 다름\n",
      "3838 7 1 다름\n",
      "3848 7 3 다름\n",
      "3853 6 5 다름\n",
      "3855 5 0 다름\n",
      "3862 2 3 다름\n",
      "3871 8 3 다름\n",
      "3876 2 8 다름\n",
      "3893 5 6 다름\n",
      "3902 5 3 다름\n",
      "3906 1 3 다름\n",
      "3926 9 3 다름\n",
      "3941 4 6 다름\n",
      "3943 3 5 다름\n",
      "3946 2 8 다름\n",
      "3951 8 2 다름\n",
      "3962 3 4 다름\n",
      "3984 9 8 다름\n",
      "3985 9 4 다름\n",
      "3988 8 5 다름\n",
      "4000 9 4 다름\n",
      "4017 4 9 다름\n",
      "4044 3 5 다름\n",
      "4063 6 5 다름\n",
      "4065 0 6 다름\n",
      "4075 8 5 다름\n",
      "4076 5 8 다름\n",
      "4078 9 7 다름\n",
      "4093 9 4 다름\n",
      "4131 5 3 다름\n",
      "4140 8 2 다름\n",
      "4145 8 3 다름\n",
      "4152 5 1 다름\n",
      "4156 2 3 다름\n",
      "4163 9 5 다름\n",
      "4173 2 4 다름\n",
      "4176 2 4 다름\n",
      "4199 7 9 다름\n",
      "4201 1 7 다름\n",
      "4205 2 1 다름\n",
      "4211 6 5 다름\n",
      "4212 1 3 다름\n",
      "4224 9 7 다름\n",
      "4238 7 9 다름\n",
      "4239 6 5 다름\n",
      "4248 2 1 다름\n",
      "4256 3 2 다름\n",
      "4271 5 3 다름\n",
      "4272 9 4 다름\n",
      "4284 9 5 다름\n",
      "4286 0 2 다름\n",
      "4289 2 7 다름\n",
      "4300 5 9 다름\n",
      "4306 3 7 다름\n",
      "4313 4 9 다름\n",
      "4315 5 8 다름\n",
      "4317 3 7 다름\n",
      "4344 9 7 다름\n",
      "4355 5 9 다름\n",
      "4356 5 8 다름\n",
      "4369 9 4 다름\n",
      "4374 5 6 다름\n",
      "4400 7 9 다름\n",
      "4415 2 0 다름\n",
      "4425 9 4 다름\n",
      "4427 2 8 다름\n",
      "4433 7 3 다름\n",
      "4435 3 7 다름\n",
      "4449 6 0 다름\n",
      "4451 2 8 다름\n",
      "4497 8 7 다름\n",
      "4498 7 9 다름\n",
      "4500 9 1 다름\n",
      "4523 8 3 다름\n",
      "4540 7 9 다름\n",
      "4571 6 2 다름\n",
      "4575 4 2 다름\n",
      "4578 7 9 다름\n",
      "4601 8 4 다름\n",
      "4615 2 4 다름\n",
      "4639 8 9 다름\n",
      "4640 8 3 다름\n",
      "4690 7 2 다름\n",
      "4731 8 7 다름\n",
      "4740 3 5 다름\n",
      "4751 4 6 다름\n",
      "4761 9 8 다름\n",
      "4785 3 8 다름\n",
      "4807 8 3 다름\n",
      "4808 3 5 다름\n",
      "4814 6 4 다름\n",
      "4823 9 4 다름\n",
      "4829 8 3 다름\n",
      "4837 7 2 다름\n",
      "4839 8 2 다름\n",
      "4852 8 6 다름\n",
      "4861 7 3 다름\n",
      "4863 8 9 다름\n",
      "4874 9 0 다름\n",
      "4876 2 4 다름\n",
      "4879 8 4 다름\n",
      "4880 0 5 다름\n",
      "4886 7 1 다름\n",
      "4890 8 6 다름\n",
      "4910 9 4 다름\n",
      "4915 5 8 다름\n",
      "4950 2 3 다름\n",
      "4956 8 4 다름\n",
      "4966 7 8 다름\n",
      "4990 3 8 다름\n",
      "5001 9 8 다름\n",
      "5038 3 2 다름\n",
      "5046 3 2 다름\n",
      "5067 3 2 다름\n",
      "5078 3 2 다름\n",
      "5140 3 4 다름\n",
      "5177 7 9 다름\n",
      "5183 8 4 다름\n",
      "5210 9 7 다름\n",
      "5331 1 6 다름\n",
      "5523 9 7 다름\n",
      "5569 8 3 다름\n",
      "5600 7 9 다름\n",
      "5611 8 1 다름\n",
      "5617 4 9 다름\n",
      "5620 7 9 다름\n",
      "5623 3 0 다름\n",
      "5634 2 0 다름\n",
      "5642 1 5 다름\n",
      "5653 0 6 다름\n",
      "5678 8 5 다름\n",
      "5714 7 9 다름\n",
      "5734 3 7 다름\n",
      "5749 8 6 다름\n",
      "5821 5 3 다름\n",
      "5835 7 9 다름\n",
      "5842 4 7 다름\n",
      "5887 7 3 다름\n",
      "5888 4 6 다름\n",
      "5891 5 6 다름\n",
      "5913 5 3 다름\n",
      "5922 5 3 다름\n",
      "5936 4 9 다름\n",
      "5937 5 3 다름\n",
      "5955 3 8 다름\n",
      "5972 5 3 다름\n",
      "5973 3 8 다름\n",
      "5975 4 9 다름\n",
      "5981 5 3 다름\n",
      "5985 5 8 다름\n",
      "6023 3 8 다름\n",
      "6035 2 0 다름\n",
      "6037 4 9 다름\n",
      "6042 5 3 다름\n",
      "6043 5 3 다름\n",
      "6045 3 8 다름\n",
      "6059 3 9 다름\n",
      "6065 3 8 다름\n",
      "6071 9 3 다름\n",
      "6081 9 8 다름\n",
      "6091 9 0 다름\n",
      "6109 2 6 다름\n",
      "6157 9 0 다름\n",
      "6160 3 8 다름\n",
      "6166 9 3 다름\n",
      "6168 9 3 다름\n",
      "6172 9 0 다름\n",
      "6173 9 0 다름\n",
      "6174 3 5 다름\n",
      "6347 8 6 다름\n",
      "6391 2 6 다름\n",
      "6400 0 6 다름\n",
      "6425 6 2 다름\n",
      "6426 0 6 다름\n",
      "6480 2 6 다름\n",
      "6505 9 0 다름\n",
      "6555 8 7 다름\n",
      "6560 9 3 다름\n",
      "6564 3 7 다름\n",
      "6568 9 4 다름\n",
      "6571 9 7 다름\n",
      "6597 0 7 다름\n",
      "6598 5 1 다름\n",
      "6603 8 7 다름\n",
      "6625 8 4 다름\n",
      "6632 9 5 다름\n",
      "6641 8 5 다름\n",
      "6642 9 4 다름\n",
      "6651 0 5 다름\n",
      "6706 5 7 다름\n",
      "6721 2 9 다름\n",
      "6744 2 6 다름\n",
      "6746 5 4 다름\n",
      "6755 8 7 다름\n",
      "6775 5 8 다름\n",
      "6785 2 4 다름\n",
      "6793 9 4 다름\n",
      "6817 9 4 다름\n",
      "6847 6 4 다름\n",
      "6926 6 4 다름\n",
      "7121 8 9 다름\n",
      "7130 3 8 다름\n",
      "7198 8 9 다름\n",
      "7210 6 8 다름\n",
      "7220 8 3 다름\n",
      "7233 3 5 다름\n",
      "7249 2 7 다름\n",
      "7265 8 3 다름\n",
      "7338 4 9 다름\n",
      "7432 7 2 다름\n",
      "7434 4 8 다름\n",
      "7451 5 6 다름\n",
      "7459 9 5 다름\n",
      "7498 5 3 다름\n",
      "7511 5 3 다름\n",
      "7545 8 9 다름\n",
      "7603 8 5 다름\n",
      "7797 5 6 다름\n",
      "7812 1 8 다름\n",
      "7821 3 2 다름\n",
      "7842 5 8 다름\n",
      "7849 3 2 다름\n",
      "7850 5 8 다름\n",
      "7859 5 6 다름\n",
      "7870 5 4 다름\n",
      "7886 2 9 다름\n",
      "7888 5 4 다름\n",
      "7917 2 4 다름\n",
      "7918 5 8 다름\n",
      "7945 2 6 다름\n",
      "7990 1 8 다름\n",
      "8010 3 2 다름\n",
      "8020 1 8 다름\n",
      "8047 2 9 다름\n",
      "8062 5 8 다름\n",
      "8072 5 3 다름\n",
      "8081 4 6 다름\n",
      "8091 2 8 다름\n",
      "8094 2 8 다름\n",
      "8095 4 8 다름\n",
      "8183 8 5 다름\n",
      "8196 6 2 다름\n",
      "8246 3 8 다름\n",
      "8272 3 8 다름\n",
      "8277 3 5 다름\n",
      "8279 8 6 다름\n",
      "8294 8 5 다름\n",
      "8308 3 5 다름\n",
      "8332 9 7 다름\n",
      "8339 8 6 다름\n",
      "8353 2 4 다름\n",
      "8406 4 9 다름\n",
      "8408 8 6 다름\n",
      "8453 5 3 다름\n",
      "8457 9 7 다름\n",
      "8519 7 3 다름\n",
      "8520 4 9 다름\n",
      "8522 8 6 다름\n",
      "8553 5 3 다름\n",
      "9007 3 8 다름\n",
      "9009 7 2 다름\n",
      "9010 2 8 다름\n",
      "9015 7 2 다름\n",
      "9019 7 2 다름\n",
      "9022 3 2 다름\n",
      "9024 7 2 다름\n",
      "9031 7 2 다름\n",
      "9036 7 2 다름\n",
      "9045 7 2 다름\n",
      "9046 2 8 다름\n",
      "9071 1 8 다름\n",
      "9182 3 8 다름\n",
      "9209 2 8 다름\n",
      "9280 8 5 다름\n",
      "9422 5 3 다름\n",
      "9427 5 3 다름\n",
      "9446 2 6 다름\n",
      "9465 5 3 다름\n",
      "9482 5 3 다름\n",
      "9534 7 9 다름\n",
      "9544 9 7 다름\n",
      "9554 9 7 다름\n",
      "9587 9 4 다름\n",
      "9595 2 8 다름\n",
      "9624 3 8 다름\n",
      "9634 0 3 다름\n",
      "9642 9 7 다름\n",
      "9643 1 7 다름\n",
      "9664 2 7 다름\n",
      "9679 6 5 다름\n",
      "9692 9 7 다름\n",
      "9698 6 5 다름\n",
      "9700 2 6 다름\n",
      "9716 2 0 다름\n",
      "9729 5 6 다름\n",
      "9732 8 5 다름\n",
      "9738 4 6 다름\n",
      "9741 9 7 다름\n",
      "9744 8 1 다름\n",
      "9745 4 2 다름\n",
      "9749 5 6 다름\n",
      "9751 2 0 다름\n",
      "9752 2 0 다름\n",
      "9764 4 8 다름\n",
      "9768 2 0 다름\n",
      "9770 5 0 다름\n",
      "9777 5 0 다름\n",
      "9779 2 0 다름\n",
      "9792 4 7 다름\n",
      "9808 9 4 다름\n",
      "9811 2 8 다름\n",
      "9839 2 7 다름\n",
      "9856 9 4 다름\n",
      "9867 2 8 다름\n",
      "9879 0 6 다름\n",
      "9883 5 1 다름\n",
      "9890 9 4 다름\n",
      "9892 8 6 다름\n",
      "9893 2 8 다름\n",
      "9901 9 4 다름\n",
      "9905 3 7 다름\n",
      "9925 3 2 다름\n",
      "9941 5 6 다름\n",
      "9943 3 8 다름\n",
      "9944 3 9 다름\n",
      "9970 5 3 다름\n",
      "9975 3 2 다름\n",
      "9980 2 3 다름\n",
      "9982 5 2 다름\n",
      "663\n"
     ]
    }
   ],
   "source": [
    "#틀린것은 왜 틀렸나?\n",
    "n=0\n",
    "for i, y in enumerate(y_test):\n",
    "    if y != y_test_pred[i]:\n",
    "        print(i,y,y_test_pred[i],\"다름\")\n",
    "        n+=1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 9986번째의 그림은 y값으로 3이 확실한데 모델이 판단하기를 8로 판단했다.\n",
    "plt.figure(figsize=(5,5))\n",
    "image = np.reshape(X_test[9986],[28,28])\n",
    "plt.imshow(image,cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN(Convolutional Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,111,946\n",
      "Trainable params: 1,111,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(5,5),padding='valid', activation='relu',input_shape=(28,28,1)))\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "model.add(layers.Conv2D(64,(5,5),padding='valid', activation='relu'))\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dropout(0.5)) ## 오버피팅을 방지함\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
