{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.FloatTensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis = F.softmax(z,dim=0)\n",
    "hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 소프트맥스 함수의 기본식"
   ]
  },
  {
   "attachments": {
    "download.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![download.png](attachment:download.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결과를 비율로 확인시켜주기 위해서 한다.\n",
    "- 등간격이었던 것을 변환시켜 큰 수를 강조시켜준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09003057317038046"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.exp(1.0)/(np.exp(1.0)+np.exp(2.0)+np.exp(3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24472847105479767"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(2.0)/(np.exp(1.0)+np.exp(2.0)+np.exp(3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6652409557748219"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(3.0)/(np.exp(1.0)+np.exp(2.0)+np.exp(3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\cpb06gamen\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\cpb06gamen\\anaconda3\\lib\\site-packages (from torchvision) (1.19.2)\n",
      "Requirement already satisfied: torch==1.9.0 in c:\\users\\cpb06gamen\\anaconda3\\lib\\site-packages (from torchvision) (1.9.0)\n",
      "Requirement already satisfied: pillow>=5.3.0 in c:\\users\\cpb06gamen\\anaconda3\\lib\\site-packages (from torchvision) (8.0.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\cpb06gamen\\anaconda3\\lib\\site-packages (from torch==1.9.0->torchvision) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                         train = True,\n",
    "                         transform = transforms.ToTensor(),\n",
    "                         download=True)\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train = False,\n",
    "                         transform = transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 15\n",
    "batch_size=100\n",
    "data_loader =torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train[0]  # 1이 넘지 않는 이유는 mnist데이터 자체가 글씨가 적혀있는 부분에 픽셀값이 조금 적혀있는 것 뿐이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 5\n"
     ]
    }
   ],
   "source": [
    "image,label = mnist_train[0]\n",
    "print(image.shape,label)    # 숫자 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 9\n"
     ]
    }
   ],
   "source": [
    "image,label = mnist_train[4]\n",
    "print(image.shape,label)   # 숫자 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#plt.imshow(image.reshape(28,28),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "linear = nn.Linear(28*28,10,bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.533649504\n",
      "Epoch: 0002 cost= 0.358642191\n",
      "Epoch: 0003 cost= 0.330779225\n",
      "Epoch: 0004 cost= 0.316260189\n",
      "Epoch: 0005 cost= 0.306741118\n",
      "Epoch: 0006 cost= 0.300162941\n",
      "Epoch: 0007 cost= 0.294817328\n",
      "Epoch: 0008 cost= 0.290684044\n",
      "Epoch: 0009 cost= 0.287285656\n",
      "Epoch: 0010 cost= 0.284258753\n",
      "Epoch: 0011 cost= 0.281809658\n",
      "Epoch: 0012 cost= 0.279576480\n",
      "Epoch: 0013 cost= 0.277836144\n",
      "Epoch: 0014 cost= 0.275776446\n",
      "Epoch: 0015 cost= 0.274397761\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "    \n",
    "    for X, y in data_loader:\n",
    "        X = X.view(-1,28*28)\n",
    "        y = y\n",
    "        \n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis,y)\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost/total_batch\n",
    "    print('Epoch:','%04d' %(epoch+1), 'cost=',\"{:.9f}\".format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8853999972343445\n",
      "Label: 0\n",
      "Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1,28*28).float()\n",
    "    y_test = mnist_test.test_labels\n",
    "    \n",
    "    prediction = linear(X_test)\n",
    "    \n",
    "    correct_prediction = torch.argmax(prediction, 1) == y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print(\"acc:\",accuracy.item())\n",
    "    r = random.randint(0, len(mnist_test)-1)\n",
    "    X_single_data = mnist_test.test_data[r:r+1].view(-1,28*28).float()\n",
    "    y_single_data = mnist_test.test_labels[r:r+1]\n",
    "    print('Label:', y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print(\"Prediction:\",torch.argmax(single_prediction,1).item())\n",
    "    \n",
    "#     plt.imshow(mnist_test.test_data[r:r+1].view(28,28), cmap='Greys',\n",
    "#               interpolation='nearest')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network - Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layering\n",
    "# nn.Linear(784,10)\n",
    "# 784 -> 256 -> 256 -> 10\n",
    "linear1 = nn.Linear(784, 256, bias = True) \n",
    "linear2 = nn.Linear(256, 256, bias = True) \n",
    "linear3 = nn.Linear(256, 10, bias = True) \n",
    "relu = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원래있던 가중치 값들을 초기화시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.4532,  0.0426, -0.1924,  ...,  0.2653,  1.8749, -0.4891],\n",
       "        [-0.5162,  0.9899, -0.0371,  ..., -0.9141,  0.8605,  1.3177],\n",
       "        [-0.2321,  0.4208, -0.0357,  ...,  1.2380,  1.2624,  0.8687],\n",
       "        ...,\n",
       "        [ 0.2614, -1.3365, -1.0296,  ...,  1.9548,  0.0199,  0.4355],\n",
       "        [ 0.2079,  0.9302,  0.2193,  ..., -1.2185, -1.8700,  1.4883],\n",
       "        [-0.2885, -0.0591, -0.8583,  ...,  0.0469,  0.3351, -0.0851]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.normal_(linear1.weight)\n",
    "nn.init.normal_(linear2.weight)\n",
    "nn.init.normal_(linear3.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# relu는 신경 전달해주는 함수이기에 중간 중간에 다른 함수들을 이어준다.\n",
    "# 또한 relu는 이미지 처리할 때 많이 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(linear1,relu,linear2,relu,linear3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 144.973587036\n",
      "Epoch: 0002 cost= 34.748874664\n",
      "Epoch: 0003 cost= 21.564258575\n",
      "Epoch: 0004 cost= 15.020461082\n",
      "Epoch: 0005 cost= 10.708985329\n",
      "Epoch: 0006 cost= 7.678145409\n",
      "Epoch: 0007 cost= 5.535806179\n",
      "Epoch: 0008 cost= 4.031185627\n",
      "Epoch: 0009 cost= 3.030933857\n",
      "Epoch: 0010 cost= 2.178589582\n",
      "Epoch: 0011 cost= 1.650301099\n",
      "Epoch: 0012 cost= 1.132889748\n",
      "Epoch: 0013 cost= 0.930800200\n",
      "Epoch: 0014 cost= 0.795090318\n",
      "Epoch: 0015 cost= 0.580806315\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "total_batch = len(data_loader)\n",
    "train_epochs = 15\n",
    "batch_size = 100\n",
    "for epoch in range(train_epochs):\n",
    "    avg_cost = 0\n",
    "    for X,y in data_loader:\n",
    "        X=X.view(-1,28*28)\n",
    "        y=y\n",
    "        optimizer.zero_grad()\n",
    "        hyp = model(X)\n",
    "        cost = criterion(hyp, y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost+=cost/total_batch\n",
    "    print('Epoch:',\"%04d\"%(epoch+1),'cost=','{:0.9f}'.format(avg_cost))\n",
    "print(\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8853999972343445\n",
      "Label: 9\n",
      "Prediction: 9\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1,28*28).float()\n",
    "    y_test = mnist_test.test_labels\n",
    "    \n",
    "    prediction = linear(X_test)\n",
    "    \n",
    "    correct_prediction = torch.argmax(prediction, 1) == y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print(\"acc:\",accuracy.item())\n",
    "    r = random.randint(0, len(mnist_test)-1)\n",
    "    X_single_data = mnist_test.test_data[r:r+1].view(-1,28*28).float()\n",
    "    y_single_data = mnist_test.test_labels[r:r+1]\n",
    "    print('Label:', y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print(\"Prediction:\",torch.argmax(single_prediction,1).item())\n",
    "    \n",
    "#     plt.imshow(mnist_test.test_data[r:r+1].view(28,28), cmap='Greys',\n",
    "#               interpolation='nearest')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
